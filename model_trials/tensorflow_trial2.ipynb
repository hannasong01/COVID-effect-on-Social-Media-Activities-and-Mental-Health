{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjYsCT5BhlACwOJQBikKRf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"bc0177bc0d4e408da43f831812b53f20":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_946dbd64ac584e31a8855d1fa996aa81","IPY_MODEL_dcb73b674a94473ca4f3bb7220003346","IPY_MODEL_abbe01e23fc546248702019268cb7b65"],"layout":"IPY_MODEL_523071f8c18f42fe84e2604e5899913b"}},"946dbd64ac584e31a8855d1fa996aa81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d553f5464ec34e1cb802933798d9a86e","placeholder":"​","style":"IPY_MODEL_8c88d65e985645a28ffbf8f1a3abb029","value":"tokenizer_config.json: 100%"}},"dcb73b674a94473ca4f3bb7220003346":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bb5b2d8c8b04c779e3633eac0f86422","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7191f75a65f64458b20011dc2c682af0","value":48}},"abbe01e23fc546248702019268cb7b65":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df731fa98b1c49d6ac0383e525042dc7","placeholder":"​","style":"IPY_MODEL_27c1d01c86c84a1ab837928e161b80a6","value":" 48.0/48.0 [00:00&lt;00:00, 2.72kB/s]"}},"523071f8c18f42fe84e2604e5899913b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d553f5464ec34e1cb802933798d9a86e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c88d65e985645a28ffbf8f1a3abb029":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bb5b2d8c8b04c779e3633eac0f86422":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7191f75a65f64458b20011dc2c682af0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"df731fa98b1c49d6ac0383e525042dc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27c1d01c86c84a1ab837928e161b80a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1853f60f502b46beb49612edf75ad3f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e53cdef5fbd5461687c47ffcac0f6d10","IPY_MODEL_9cde456300cf46d59db5bb20906fe17a","IPY_MODEL_c0b746d6d5694d2ea2c4a712ee47f9bc"],"layout":"IPY_MODEL_cf0a2890649543f592e3b962691b6ff1"}},"e53cdef5fbd5461687c47ffcac0f6d10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94bdaf169f0e45ac88c799b9379325ad","placeholder":"​","style":"IPY_MODEL_309acf250c4749309c0b82080b13b1c1","value":"vocab.txt: 100%"}},"9cde456300cf46d59db5bb20906fe17a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68ff1edd3a604be69cfbe6448814c43a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4dff84319fa44956b8ed626b8d3111ee","value":231508}},"c0b746d6d5694d2ea2c4a712ee47f9bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4458a50c287d496194d1829ac3cfadfb","placeholder":"​","style":"IPY_MODEL_bc3cde999f3a4322b618adce9451bdc3","value":" 232k/232k [00:00&lt;00:00, 2.91MB/s]"}},"cf0a2890649543f592e3b962691b6ff1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94bdaf169f0e45ac88c799b9379325ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"309acf250c4749309c0b82080b13b1c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68ff1edd3a604be69cfbe6448814c43a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4dff84319fa44956b8ed626b8d3111ee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4458a50c287d496194d1829ac3cfadfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc3cde999f3a4322b618adce9451bdc3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90c6db4712854e6a915c10c0d241288e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40d3dade85ec4845acfee86318129d6d","IPY_MODEL_410173f0c5374c45a1d73b2dee062162","IPY_MODEL_a7badd5faaec4c71ba91856a7eaa3c69"],"layout":"IPY_MODEL_36bc1e88c85f42fab8d0b42d0b785f4d"}},"40d3dade85ec4845acfee86318129d6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5be1b3796e074e269b66233cc7e71770","placeholder":"​","style":"IPY_MODEL_b0af13a22a8940d2b6717417f3bb0c26","value":"tokenizer.json: 100%"}},"410173f0c5374c45a1d73b2dee062162":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_90df2a27ccde43c9aa9cd869b287c9cb","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_970fad28702a461092bad4f0600eb611","value":466062}},"a7badd5faaec4c71ba91856a7eaa3c69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b21b07681bc8492ab809b5f4af66317f","placeholder":"​","style":"IPY_MODEL_d62f663f60c2442db810167691bec0ad","value":" 466k/466k [00:00&lt;00:00, 2.31MB/s]"}},"36bc1e88c85f42fab8d0b42d0b785f4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5be1b3796e074e269b66233cc7e71770":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0af13a22a8940d2b6717417f3bb0c26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90df2a27ccde43c9aa9cd869b287c9cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"970fad28702a461092bad4f0600eb611":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b21b07681bc8492ab809b5f4af66317f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d62f663f60c2442db810167691bec0ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8bfbea1444a42548f6afbba73e99440":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1da025e2e2ed457e94a1dcc3ae48965c","IPY_MODEL_e3e56a5e40384e8b93033e4bc4e4373c","IPY_MODEL_6345381910c04e0a8ae690323a30b158"],"layout":"IPY_MODEL_36e4653506944266942cbb57d076928f"}},"1da025e2e2ed457e94a1dcc3ae48965c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e85221baec0427fb0f2e549051a32bc","placeholder":"​","style":"IPY_MODEL_071ac8c43fc94168b9e63b2358bcaa9a","value":"config.json: 100%"}},"e3e56a5e40384e8b93033e4bc4e4373c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a6c4288cc5947e1b655b88cf3887d37","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aea2943e676440868d6ed0abe770713f","value":570}},"6345381910c04e0a8ae690323a30b158":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf6313708cb74a4293bdd38940cfca99","placeholder":"​","style":"IPY_MODEL_19318a2f5d284480a4b48e5b79ed3ed7","value":" 570/570 [00:00&lt;00:00, 38.3kB/s]"}},"36e4653506944266942cbb57d076928f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e85221baec0427fb0f2e549051a32bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"071ac8c43fc94168b9e63b2358bcaa9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a6c4288cc5947e1b655b88cf3887d37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aea2943e676440868d6ed0abe770713f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bf6313708cb74a4293bdd38940cfca99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19318a2f5d284480a4b48e5b79ed3ed7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"mkzscnd6qmnY","executionInfo":{"status":"ok","timestamp":1712780817766,"user_tz":240,"elapsed":24569,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"outputs":[],"source":["import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer, TFBertModel\n","from tensorflow.keras.layers import Input, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.layers import GlobalAveragePooling1D, Concatenate\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.sequence import pad_sequences"]},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from transformers import TFBertForSequenceClassification\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, LSTM, BatchNormalization\n","from keras.callbacks import TensorBoard\n","from keras.callbacks import ModelCheckpoint\n","#from tensorflow.keras.optimizers import Adam\n","from tensorflow.python.keras.optimizers import adam_v2"],"metadata":{"id":"c2qEH636myKN","executionInfo":{"status":"ok","timestamp":1712780819015,"user_tz":240,"elapsed":1254,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["tf.config.run_functions_eagerly(True)"],"metadata":{"id":"JiPNHTRzRI7S","executionInfo":{"status":"ok","timestamp":1712780819016,"user_tz":240,"elapsed":3,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2VE5C1HVaCz","executionInfo":{"status":"ok","timestamp":1712780886659,"user_tz":240,"elapsed":67645,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"86ac3d75-0671-4acd-d0a8-03f7802f505a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["path = \"/content/drive/My Drive/Capstone/data/depression_pre.csv\"\n","dp = pd.read_csv(path)"],"metadata":{"id":"JZ8s0qqfVar4","executionInfo":{"status":"ok","timestamp":1712780911553,"user_tz":240,"elapsed":1234,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["path2 = \"/content/drive/My Drive/Capstone/data/depression_post.csv\"\n","dp_post = pd.read_csv(path2)"],"metadata":{"id":"Dk5Tyhr0WjtY","executionInfo":{"status":"ok","timestamp":1712780912121,"user_tz":240,"elapsed":569,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["pre = dp.drop(columns=['Unnamed: 0', 'Post URL', 'Original Content', 'Saved','ID', 'year', 'month'])"],"metadata":{"id":"O8WW3C8npK0J","executionInfo":{"status":"ok","timestamp":1712780915464,"user_tz":240,"elapsed":205,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["post = dp_post.drop(columns=['Unnamed: 0', 'Post URL', 'Original Content', 'Saved','ID', 'year', 'month'])"],"metadata":{"id":"lK-yDUkWtR7k","executionInfo":{"status":"ok","timestamp":1712780920265,"user_tz":240,"elapsed":3,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["pre_txt = pre[[\"Post Text\"]]\n","post_txt = post[[\"Post Text\"]]"],"metadata":{"id":"LIhvd-YSJqy_","executionInfo":{"status":"ok","timestamp":1712780920837,"user_tz":240,"elapsed":4,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["pre_txt['label'] = 'pre'\n","post_txt['label'] = 'post'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqRoDcfxWGMd","executionInfo":{"status":"ok","timestamp":1712780921533,"user_tz":240,"elapsed":5,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"01e258c3-7ca2-488b-9f00-e96ed2c23406"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-11-26faaad642e7>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  pre_txt['label'] = 'pre'\n","<ipython-input-11-26faaad642e7>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  post_txt['label'] = 'post'\n"]}]},{"cell_type":"code","source":["pre_txt['Post Text'] = pre_txt['Post Text'].values\n","post_txt['Post Text'] = post_txt['Post Text'].values"],"metadata":{"id":"fdLeVtdJsGBN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712780924042,"user_tz":240,"elapsed":188,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"aff3e3e9-9126-4b83-f16c-d305d1684cfa"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-12-714712031f77>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  pre_txt['Post Text'] = pre_txt['Post Text'].values\n","<ipython-input-12-714712031f77>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  post_txt['Post Text'] = post_txt['Post Text'].values\n"]}]},{"cell_type":"code","source":["pre_txt['Post Text'].fillna('', inplace=True)\n","pre_txt.dropna(subset=['Post Text'], inplace=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"06AyrCUJuCeF","executionInfo":{"status":"ok","timestamp":1712780924329,"user_tz":240,"elapsed":1,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"37f3a16c-e1d5-4542-fc6a-b1f14780bd8b"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-7f9de0dda555>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  pre_txt['Post Text'].fillna('', inplace=True)\n","<ipython-input-13-7f9de0dda555>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  pre_txt.dropna(subset=['Post Text'], inplace=True)\n"]}]},{"cell_type":"code","source":["post_txt['Post Text'].fillna('', inplace=True)\n","post_txt.dropna(subset=['Post Text'], inplace=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOBKcyCIRIj_","executionInfo":{"status":"ok","timestamp":1712780924848,"user_tz":240,"elapsed":5,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"088102e7-aad0-4374-be49-049a8443b9c0"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-14-60cd906aa43a>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  post_txt['Post Text'].fillna('', inplace=True)\n","<ipython-input-14-60cd906aa43a>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  post_txt.dropna(subset=['Post Text'], inplace=True)\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"metadata":{"id":"-LhmnSjTpfjo","executionInfo":{"status":"ok","timestamp":1712780929234,"user_tz":240,"elapsed":2658,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["bc0177bc0d4e408da43f831812b53f20","946dbd64ac584e31a8855d1fa996aa81","dcb73b674a94473ca4f3bb7220003346","abbe01e23fc546248702019268cb7b65","523071f8c18f42fe84e2604e5899913b","d553f5464ec34e1cb802933798d9a86e","8c88d65e985645a28ffbf8f1a3abb029","2bb5b2d8c8b04c779e3633eac0f86422","7191f75a65f64458b20011dc2c682af0","df731fa98b1c49d6ac0383e525042dc7","27c1d01c86c84a1ab837928e161b80a6","1853f60f502b46beb49612edf75ad3f7","e53cdef5fbd5461687c47ffcac0f6d10","9cde456300cf46d59db5bb20906fe17a","c0b746d6d5694d2ea2c4a712ee47f9bc","cf0a2890649543f592e3b962691b6ff1","94bdaf169f0e45ac88c799b9379325ad","309acf250c4749309c0b82080b13b1c1","68ff1edd3a604be69cfbe6448814c43a","4dff84319fa44956b8ed626b8d3111ee","4458a50c287d496194d1829ac3cfadfb","bc3cde999f3a4322b618adce9451bdc3","90c6db4712854e6a915c10c0d241288e","40d3dade85ec4845acfee86318129d6d","410173f0c5374c45a1d73b2dee062162","a7badd5faaec4c71ba91856a7eaa3c69","36bc1e88c85f42fab8d0b42d0b785f4d","5be1b3796e074e269b66233cc7e71770","b0af13a22a8940d2b6717417f3bb0c26","90df2a27ccde43c9aa9cd869b287c9cb","970fad28702a461092bad4f0600eb611","b21b07681bc8492ab809b5f4af66317f","d62f663f60c2442db810167691bec0ad","a8bfbea1444a42548f6afbba73e99440","1da025e2e2ed457e94a1dcc3ae48965c","e3e56a5e40384e8b93033e4bc4e4373c","6345381910c04e0a8ae690323a30b158","36e4653506944266942cbb57d076928f","4e85221baec0427fb0f2e549051a32bc","071ac8c43fc94168b9e63b2358bcaa9a","8a6c4288cc5947e1b655b88cf3887d37","aea2943e676440868d6ed0abe770713f","bf6313708cb74a4293bdd38940cfca99","19318a2f5d284480a4b48e5b79ed3ed7"]},"outputId":"79de7d61-74f7-45f1-c33a-57422a86e26e"},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc0177bc0d4e408da43f831812b53f20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1853f60f502b46beb49612edf75ad3f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90c6db4712854e6a915c10c0d241288e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8bfbea1444a42548f6afbba73e99440"}},"metadata":{}}]},{"cell_type":"code","source":["import string\n","string.punctuation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"u1_pmpEEL7sw","executionInfo":{"status":"ok","timestamp":1712780929234,"user_tz":240,"elapsed":7,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"7d8a8164-d520-4c6c-dff4-3ff407e55619"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["def remove_punctuations(text):\n","    for punctuation in string.punctuation:\n","        text = text.replace(punctuation, '')\n","    return text"],"metadata":{"id":"ZkG5D4gMMBI4","executionInfo":{"status":"ok","timestamp":1712780929234,"user_tz":240,"elapsed":6,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["pre_txt['Post Text'] = pre_txt['Post Text'].apply(remove_punctuations)\n","post_txt['Post Text'] = post_txt['Post Text'].apply(remove_punctuations)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_JKYTkgbN3Nw","executionInfo":{"status":"ok","timestamp":1712780929234,"user_tz":240,"elapsed":6,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"54a3593e-9756-4f0e-eafd-2a2b6688b7bf"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-18-ccfe400b5707>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  pre_txt['Post Text'] = pre_txt['Post Text'].apply(remove_punctuations)\n","<ipython-input-18-ccfe400b5707>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  post_txt['Post Text'] = post_txt['Post Text'].apply(remove_punctuations)\n"]}]},{"cell_type":"code","source":["pre_txt['Post Text'] = pre_txt['Post Text'].replace('\\n','', regex=True)\n","post_txt['Post Text'] = post_txt['Post Text'].replace('\\n','', regex=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uD8hxe2YO1ty","executionInfo":{"status":"ok","timestamp":1712780929933,"user_tz":240,"elapsed":3,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"e04b1813-7019-4cd7-ada7-ea9ce5a76a25"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-19-a13db772377b>:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  pre_txt['Post Text'] = pre_txt['Post Text'].replace('\\n','', regex=True)\n","<ipython-input-19-a13db772377b>:2: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  post_txt['Post Text'] = post_txt['Post Text'].replace('\\n','', regex=True)\n"]}]},{"cell_type":"code","source":["post_txt['Post Text'].iloc[1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"n5UK0EDGLJkA","executionInfo":{"status":"ok","timestamp":1712780931673,"user_tz":240,"elapsed":7,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"bbd745e0-fb13-4909-a284-8e00bfb88524"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Im never going to get better why the fuck should I even try'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["# Function to tokenize and encode text\n","def tokenize_and_encode(text, label):\n","    text = text.numpy().decode()  # Convert symbolic tensor to string\n","    tokens = tokenizer.encode_plus(text,\n","                                   max_length=128,  # Adjust max_length as needed\n","                                   truncation=True,\n","                                   padding='max_length',\n","                                   add_special_tokens=True,\n","                                   return_attention_mask=True,\n","                                   return_token_type_ids=True)\n","    return {'input_ids': tokens['input_ids'],\n","            'token_type_ids': tokens['token_type_ids'],\n","            'attention_mask': tokens['attention_mask']}, label\n"],"metadata":{"id":"GtbAv-L-S3RM","executionInfo":{"status":"ok","timestamp":1712780941375,"user_tz":240,"elapsed":242,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# Tokenize and encode data\n","pre_covid_tokens = [(text, 0) for text in pre_txt['Post Text']]  # Encode 'pre' as 0\n","post_covid_tokens = [(text, 1) for text in post_txt['Post Text']]  # Encode 'post' as 1\n","\n","# Combine datasets\n","all_tokens = pre_covid_tokens + post_covid_tokens\n","\n","# Shuffle dataset\n","import random\n","random.shuffle(all_tokens)\n","# Convert to TensorFlow dataset\n","dataset = tf.data.Dataset.from_generator(lambda: all_tokens,\n","                                         output_types=(tf.string, tf.int64),\n","                                         output_shapes=((), ()))\n","\n","# Tokenize and encode data within the dataset using tf.py_function\n","def tokenize_encode_wrapper(text, label):\n","    return tf.py_function(tokenize_and_encode, inp=[text, label], Tout=(tf.int32, tf.int64))\n","\n","dataset = dataset.map(tokenize_encode_wrapper)\n","\n","# Define model configuration\n","model_config = {\n","    \"num_labels\": 2,  # Number of output labels (pre-COVID, post-COVID)\n","    \"output_attentions\": False,\n","    \"output_hidden_states\": False\n","}\n","\n","\n","# Load pre-trained BERT model for sequence classification\n","bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", **model_config)\n","\n","# Compile the model\n","bert_model.compile(optimizer='adam',  # Use string identifier for optimizer\n","                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                   metrics=['accuracy'])\n","\n","# Train the model\n","bert_model.fit(dataset.shuffle(len(all_tokens)).batch(8), epochs=3)\n","\n","\n"],"metadata":{"id":"uwvhcb0kS3O_","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1712781058429,"user_tz":240,"elapsed":8797,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"3897f77e-ecf6-47dd-9364-1011713a9989"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n","\n","Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Attempt to convert a value ({'input_ids': [101, 2059, 2008, 2711, 5363, 2000, 2735, 2009, 8380, 7737, 1998, 7566, 2055, 4933, 2008, 3084, 2032, 6517, 5685, 2043, 2057, 2202, 2256, 3268, 2111, 2360, 2339, 2134, 2102, 2027, 3713, 2138, 2053, 2303, 2003, 2412, 2183, 2000, 4952, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}) with an unsupported type (<class 'dict'>) to a Tensor.\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 162, in _call\n    outputs = [\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 163, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 130, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 696, in convert_to_tensor\n    return tensor_conversion_registry.convert(\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 335, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 142, in wrapper\n    return op(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 284, in _constant_impl\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 296, in _constant_eager_impl\n    t = convert_to_eager_tensor(value, ctx, dtype)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 103, in convert_to_eager_tensor\n    return ops.EagerTensor(value, ctx.device_name, dtype)\n\nValueError: Attempt to convert a value ({'input_ids': [101, 2059, 2008, 2711, 5363, 2000, 2735, 2009, 8380, 7737, 1998, 7566, 2055, 4933, 2008, 3084, 2032, 6517, 5685, 2043, 2057, 2202, 2256, 3268, 2111, 2360, 2339, 2134, 2102, 2027, 3713, 2138, 2053, 2303, 2003, 2412, 2183, 2000, 4952, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}) with an unsupported type (<class 'dict'>) to a Tensor.\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-1bc1731eefa5>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_batch_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Attempt to convert a value ({'input_ids': [101, 2059, 2008, 2711, 5363, 2000, 2735, 2009, 8380, 7737, 1998, 7566, 2055, 4933, 2008, 3084, 2032, 6517, 5685, 2043, 2057, 2202, 2256, 3268, 2111, 2360, 2339, 2134, 2102, 2027, 3713, 2138, 2053, 2303, 2003, 2412, 2183, 2000, 4952, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 162, in _call\n    outputs = [\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 163, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 130, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 696, in convert_to_tensor\n    return tensor_conversion_registry.convert(\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 335, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 142, in wrapper\n    return op(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 284, in _constant_impl\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 296, in _constant_eager_impl\n    t = convert_to_eager_tensor(value, ctx, dtype)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 103, in convert_to_eager_tensor\n    return ops.EagerTensor(value, ctx.device_name, dtype)\n\nValueError: Attempt to convert a value ({'input_ids': [101, 2059, 2008, 2711, 5363, 2000, 2735, 2009, 8380, 7737, 1998, 7566, 2055, 4933, 2008, 3084, 2032, 6517, 5685, 2043, 2057, 2202, 2256, 3268, 2111, 2360, 2339, 2134, 2102, 2027, 3713, 2138, 2053, 2303, 2003, 2412, 2183, 2000, 4952, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}) with an unsupported type (<class 'dict'>) to a Tensor.\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"dJ33KDiUS3MH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xkMnMnIuS3I9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sG3uLBeBS3Gk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_and_encode(text, label):\n","  tokens = tokenizer.encode_plus(text.numpy().decode(),\n","                                 max_length=128,\n","                                 truncation=True,\n","                                 padding='max_length',\n","                                 add_special_tokens=True,\n","                                 return_attention_mask=True,\n","                                 return_token_type_ids=True,\n","                                 return_tensors='tf')\n","  return {'input_ids': tokens['input_ids'][0],\n","            'token_type_ids': tokens['token_type_ids'][0],\n","            'attention_mask': tokens['attention_mask'][0]}, label"],"metadata":{"id":"zZcdhyIrpjb9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pre_tokens = [(text, 0) for text in pre_txt['Post Text']]  # Encode 'pre' as 0\n","post_tokens = [(text, 1) for text in post_txt['Post Text']]  # Encode 'post' as 1"],"metadata":{"id":"8YEpQzSr7mZu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_tokens = pre_tokens + post_tokens"],"metadata":{"id":"I3G3wQgZ7yPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["texts = [text for text, _ in all_tokens]\n","labels = [label for _, label in all_tokens]"],"metadata":{"id":"P7La1o76BdYa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = tf.constant(labels)"],"metadata":{"id":"uNZeTyDdBhWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","random.shuffle(all_tokens)"],"metadata":{"id":"tmOiV1D87602"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_generator(lambda: all_tokens,\n","                                         output_types=(tf.string, tf.int64),\n","                                         output_shapes=((), ()))"],"metadata":{"id":"VR7AIwds9R17"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenize_encode_wrapper(text, label):\n","    return tf.py_function(tokenize_and_encode, inp=[text, label], Tout=(tf.int32, tf.int64))\n","\n","dataset = dataset.map(tokenize_encode_wrapper)"],"metadata":{"id":"Rxu8zt8Y9UVN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_config = {\n","    \"num_labels\": 2,  # Number of output labels (pre-COVID, post-COVID)\n","    \"output_attentions\": False,\n","    \"output_hidden_states\": False\n","}"],"metadata":{"id":"yhboeoST_uEO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", **model_config)\n","\n","# Compile the model\n","bert_model.compile(optimizer='adam',  # Use string identifier for optimizer\n","                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","                   metrics=['accuracy'])\n","\n","# Train the model\n","bert_model.fit(dataset.shuffle(len(all_tokens)).batch(32), epochs=3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"X5ro5P3s_ofW","executionInfo":{"status":"error","timestamp":1712622715989,"user_tz":240,"elapsed":7990,"user":{"displayName":"Hanna Song","userId":"04015947984786391173"}},"outputId":"c5a4e45b-f5b8-4ba6-ace4-a416abc0974c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n","\n","Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Attempt to convert a value ({'input_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([  101,  1045,  2123,  1521,  1056,  2113,  2065, 10334,  2842,\n        2064, 14396,  2000,  2023,  2021,  2823,  1045,  4299,  1045,\n        2001,  2074,  2730,  1045,  2123,  1521,  1056,  2215,  2000,\n        3102,  2870,  2138,  1045,  2514,  2066,  2026, 12954,  2052,\n        2228,  2009,  1521,  1055,  2014,  6346,  2008,  1045,  1521,\n        1049,  2025,  2105,  4902,  1045,  2113,  2009,  2876,  1521,\n        1056,  2022,  2026,  3291,  4902,  2021,  2012,  1996,  2168,\n        2051,  1045,  2123,  1521,  1056,  2113,  2129,  2000,  4863,\n        2009,  1045,  2074,  2876,  1521,  1056,  2215,  2014,  2000,\n        2514,  2066,  2016,  2071,  2031,  2589,  2242,  2000,  2562,\n        2033,  2105,  2074,  2245,  1045,  1521,  1040,  2681,  2023,\n        2182,   102,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>}) with an unsupported type (<class 'dict'>) to a Tensor.\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 162, in _call\n    outputs = [\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 163, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 130, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 696, in convert_to_tensor\n    return tensor_conversion_registry.convert(\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 335, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 142, in wrapper\n    return op(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 284, in _constant_impl\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 296, in _constant_eager_impl\n    t = convert_to_eager_tensor(value, ctx, dtype)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 103, in convert_to_eager_tensor\n    return ops.EagerTensor(value, ctx.device_name, dtype)\n\nValueError: Attempt to convert a value ({'input_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([  101,  1045,  2123,  1521,  1056,  2113,  2065, 10334,  2842,\n        2064, 14396,  2000,  2023,  2021,  2823,  1045,  4299,  1045,\n        2001,  2074,  2730,  1045,  2123,  1521,  1056,  2215,  2000,\n        3102,  2870,  2138,  1045,  2514,  2066,  2026, 12954,  2052,\n        2228,  2009,  1521,  1055,  2014,  6346,  2008,  1045,  1521,\n        1049,  2025,  2105,  4902,  1045,  2113,  2009,  2876,  1521,\n        1056,  2022,  2026,  3291,  4902,  2021,  2012,  1996,  2168,\n        2051,  1045,  2123,  1521,  1056,  2113,  2129,  2000,  4863,\n        2009,  1045,  2074,  2876,  1521,  1056,  2215,  2014,  2000,\n        2514,  2066,  2016,  2071,  2031,  2589,  2242,  2000,  2562,\n        2033,  2105,  2074,  2245,  1045,  1521,  1040,  2681,  2023,\n        2182,   102,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>}) with an unsupported type (<class 'dict'>) to a Tensor.\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-e1b3d4396bd8>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mbert_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_batch_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ValueError: Attempt to convert a value ({'input_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([  101,  1045,  2123,  1521,  1056,  2113,  2065, 10334,  2842,\n        2064, 14396,  2000,  2023,  2021,  2823,  1045,  4299,  1045,\n        2001,  2074,  2730,  1045,  2123,  1521,  1056,  2215,  2000,\n        3102,  2870,  2138,  1045,  2514,  2066,  2026, 12954,  2052,\n        2228,  2009,  1521,  1055,  2014,  6346,  2008,  1045,  1521,\n        1049,  2025,  2105,  4902,  1045,  2113,  2009,  2876,  1521,\n        1056,  2022,  2026,  3291,  4902,  2021,  2012,  1996,  2168,\n        2051,  1045,  2123,  1521,  1056,  2113,  2129,  2000,  4863,\n        2009,  1045,  2074,  2876,  1521,  1056,  2215,  2014,  2000,\n        2514,  2066,  2016,  2071,  2031,  2589,  2242,  2000,  2562,\n        2033,  2105,  2074,  2245,  1045,  1521,  1040,  2681,  2023,\n        2182,   102,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>}) with an unsupported type (<class 'dict'>) to a Tensor.\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 146, in __call__\n    outputs = self._call(device, args)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 162, in _call\n    outputs = [\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 163, in <listcomp>\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/script_ops.py\", line 130, in _convert\n    return ops.convert_to_tensor(value, dtype=dtype)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/profiler/trace.py\", line 183, in wrapped\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\", line 696, in convert_to_tensor\n    return tensor_conversion_registry.convert(\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 234, in convert\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 335, in _constant_tensor_conversion_function\n    return constant(v, dtype=dtype, name=name)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\", line 142, in wrapper\n    return op(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 284, in _constant_impl\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 296, in _constant_eager_impl\n    t = convert_to_eager_tensor(value, ctx, dtype)\n\n  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/constant_op.py\", line 103, in convert_to_eager_tensor\n    return ops.EagerTensor(value, ctx.device_name, dtype)\n\nValueError: Attempt to convert a value ({'input_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([  101,  1045,  2123,  1521,  1056,  2113,  2065, 10334,  2842,\n        2064, 14396,  2000,  2023,  2021,  2823,  1045,  4299,  1045,\n        2001,  2074,  2730,  1045,  2123,  1521,  1056,  2215,  2000,\n        3102,  2870,  2138,  1045,  2514,  2066,  2026, 12954,  2052,\n        2228,  2009,  1521,  1055,  2014,  6346,  2008,  1045,  1521,\n        1049,  2025,  2105,  4902,  1045,  2113,  2009,  2876,  1521,\n        1056,  2022,  2026,  3291,  4902,  2021,  2012,  1996,  2168,\n        2051,  1045,  2123,  1521,  1056,  2113,  2129,  2000,  4863,\n        2009,  1045,  2074,  2876,  1521,  1056,  2215,  2014,  2000,\n        2514,  2066,  2016,  2071,  2031,  2589,  2242,  2000,  2562,\n        2033,  2105,  2074,  2245,  1045,  1521,  1040,  2681,  2023,\n        2182,   102,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0,     0,     0,     0,     0,     0,     0,     0,\n           0,     0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(128,), dtype=int32, numpy=\narray([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>}) with an unsupported type (<class 'dict'>) to a Tensor.\n\n\n\t [[{{node EagerPyFunc}}]] [Op:IteratorGetNext] name: "]}]},{"cell_type":"code","source":[],"metadata":{"id":"flVdKFdo_ocg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4ubTWoo0_oYq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zb17GRtI_oVv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#pre_tokens = [(text, label) for text, label in zip(pre_txt['Post Text'], pre_txt['label'])]\n","#post_tokens = [(text, label) for text, label in zip(post_txt['Post Text'], post_txt['label'])]\n","\n","\n","#pre_covid tokenize_and_encode(text) for text in pre_txt['Post Text']]\n","\n","#post_tokens = [tokenize_and_encode(text) for text in post_txt['Post Text']]"],"metadata":{"id":"DKRitkBgqgfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pre_df = tf.data.Dataset.from_generator(lambda: (tokenize_and_encode(text, label) for text, label in pre_tokens),\n","                                                   output_types=({'input_ids': tf.int32,\n","                                                                  'token_type_ids': tf.int32,\n","                                                                  'attention_mask': tf.int32},\n","                                                                 tf.int64),\n","                                                   output_shapes=({'input_ids': (128,),\n","                                                                   'token_type_ids': (128,),\n","                                                                   'attention_mask': (128,)},\n","                                                                  ()))\n","\n","post_df = tf.data.Dataset.from_generator(lambda: (tokenize_and_encode(text, label) for text, label in post_tokens),\n","                                                   output_types=({'input_ids': tf.int32,\n","                                                                  'token_type_ids': tf.int32,\n","                                                                  'attention_mask': tf.int32},\n","                                                                 tf.int64),\n","                                                   output_shapes=({'input_ids': (128,),\n","                                                                   'token_type_ids': (128,),\n","                                                                   'attention_mask': (128,)},\n","                                                                  ()))"],"metadata":{"id":"N3UUIqQ-2Vu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"72yj7rGWtmP6"},"execution_count":null,"outputs":[]}]}